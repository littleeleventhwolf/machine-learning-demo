{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras使用陷阱\n",
    "\n",
    "这里归纳了Keras使用过程中的一些常见陷阱和解决方法，如果你的模型怎么调都不对，或许你有必要看看是不是掉进了哪个猎人的陷阱，成为一只嗷嗷待宰的猎物。\n",
    "\n",
    "Keras陷阱不多，我们保持更新，希望能够做一个陷阱大全。\n",
    "\n",
    "内有恶犬，小心哟。\n",
    "\n",
    "## TF卷积核与TH卷积核\n",
    "\n",
    "Keras提供了两套后端，Theano和Tensorflow，这是一件幸福的事，就像手中拿着馒头，想蘸红糖蘸红糖，想蘸白糖蘸白糖。\n",
    "\n",
    "如果你从无到有搭建自己的一套网络，则大可放心。但如果你使用一个已有的网络，或把一个用th/tf训练的网络以另一种后端应用，在载入的时候你就应该特别小心了。\n",
    "\n",
    "卷积核与所使用的后端不匹配，不会报任何错误，因为它们的shape是完全一致的，没有方法能够检测出这种错误。\n",
    "\n",
    "在使用预训练模型时，一个建议是首先找到一些测试样本，看看模型的表现是否与预计的一致。\n",
    "\n",
    "如果对卷积核进行转换，可以使用utils.convert_all_kernals_in_model对模型的所有卷积核进行转换。\n",
    "\n",
    "## 向BN层中载入权重\n",
    "\n",
    "如果你不知道从哪里淘来了一个预训练好的BN层，想把它的权重载入到Keras中，要小心参数的载入顺序。\n",
    "\n",
    "一个典型的例子是，将caffe的BN层参数载入Keras中，caffe的BN由两部分构成，BN层的参数是mean，std，Scale层的参数是gamma，beta。\n",
    "\n",
    "按照BN的文章顺序，似乎载入Keras BN层的参数应是\\[mean, std, gamma, beta\\]。\n",
    "\n",
    "然而不是的，Keras的BN层参数顺序应该是\\[gamma, beta, mean, std\\]，这是因为gamma和beta是可训练参数，而mean和std不是。\n",
    "\n",
    "Keras的可训练参数在前，不可训练参数在后。\n",
    "\n",
    "错误的权重顺序不会引起任何报错，因为它们的shape完全相同。\n",
    "\n",
    "## shuffle和validation_split的顺序\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
